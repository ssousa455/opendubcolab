import gradio as gr
import os
import subprocess
import torch
import shutil
import tempfile
import json
import sys
from pathlib import Path
import logging
from typing import Optional, Tuple, List
import time

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ConfiguraÃ§Ãµes globais
MAX_FILE_SIZE = 500 * 1024 * 1024  # 500MB
SUPPORTED_FORMATS = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']

class OpenDubbingApp:
    def __init__(self):
        self.setup_environment()
        self.output_dir = Path("./outputs")
        self.output_dir.mkdir(exist_ok=True)
        
    def setup_environment(self):
        """Configurar ambiente para usar GPU se disponÃ­vel"""
        if torch.cuda.is_available():
            os.environ["CUDA_VISIBLE_DEVICES"] = "0"
            os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:128"
            logger.info(f"GPU detectada: {torch.cuda.get_device_name(0)}")
            logger.info(f"MemÃ³ria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            logger.warning("GPU nÃ£o disponÃ­vel, usando CPU")
            
    def validate_inputs(self, video_file, target_language, hf_token) -> Tuple[bool, str]:
        """Validar entradas do usuÃ¡rio"""
        if not video_file:
            return False, "âŒ Por favor, selecione um arquivo de vÃ­deo"
            
        if not hf_token:
            return False, "âŒ Token HuggingFace Ã© obrigatÃ³rio"
            
        if not target_language:
            return False, "âŒ Selecione um idioma de destino"
            
        # Verificar tamanho do arquivo
        if os.path.getsize(video_file) > MAX_FILE_SIZE:
            return False, f"âŒ Arquivo muito grande (max: {MAX_FILE_SIZE/1024/1024:.0f}MB)"
            
        # Verificar formato
        if not any(video_file.lower().endswith(fmt) for fmt in SUPPORTED_FORMATS):
            return False, f"âŒ Formato nÃ£o suportado. Use: {', '.join(SUPPORTED_FORMATS)}"
            
        return True, "âœ… ValidaÃ§Ã£o ok"
        
    def process_video(self, video_file, target_language, hf_token, 
                     source_language="auto", tts_engine="edge", 
                     use_gpu=True, progress=gr.Progress()):
        """Processar dublagem do vÃ­deo"""
        
        # Validar entradas
        is_valid, message = self.validate_inputs(video_file, target_language, hf_token)
        if not is_valid:
            return None, message, ""
            
        progress(0.1, "ğŸ” Validando arquivos...")
        
        try:
            # Preparar diretÃ³rio de saÃ­da
            timestamp = int(time.time())
            output_name = f"dubbed_{timestamp}.mp4"
            output_path = self.output_dir / output_name
            
            progress(0.2, "ğŸš€ Iniciando dublagem...")
            
            # Construir comando
            cmd = [
                "python", "-m", "open_dubbing",
                "--input_file", str(video_file),
                "--target_language", target_language,
                "--hugging_face_token", hf_token,
                "--output_directory", str(self.output_dir),
                "--tts_engine", tts_engine,
                "--output_name", output_name
            ]
            
            # Adicionar opÃ§Ãµes condicionais
            if source_language != "auto":
                cmd.extend(["--source_language", source_language])
                
            if use_gpu and torch.cuda.is_available():
                cmd.extend(["--device", "cuda"])
            else:
                cmd.extend(["--device", "cpu"])
                
            progress(0.3, "ğŸ¬ Processando vÃ­deo...")
            
            # Executar comando
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                universal_newlines=True
            )
            
            # Monitorar progresso
            for i in range(30, 90, 5):
                if process.poll() is not None:
                    break
                progress(i/100, f"ğŸ”„ Processando... ({i}%)")
                time.sleep(2)
                
            # Aguardar conclusÃ£o
            stdout, stderr = process.communicate()
            
            progress(0.95, "ğŸ‰ Finalizando...")
            
            if process.returncode == 0:
                if output_path.exists():
                    file_size = output_path.stat().st_size / 1024 / 1024
                    success_msg = f"âœ… Dublagem concluÃ­da com sucesso!\nğŸ“ Arquivo: {output_name}\nğŸ“Š Tamanho: {file_size:.1f}MB"
                    progress(1.0, "âœ… ConcluÃ­do!")
                    return str(output_path), success_msg, ""
                else:
                    return None, "âŒ Arquivo de saÃ­da nÃ£o encontrado", stderr
            else:
                error_msg = f"âŒ Erro no processamento:\n{stderr}"
                return None, error_msg, stderr
                
        except Exception as e:
            error_msg = f"âŒ Erro inesperado: {str(e)}"
            logger.error(error_msg)
            return None, error_msg, str(e)
            
    def get_system_info(self):
        """Obter informaÃ§Ãµes do sistema"""
        info = []
        
        # GPU Info
        if torch.cuda.is_available():
            info.append(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
            info.append(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            info.append(f"ğŸ”¥ CUDA: {torch.version.cuda}")
        else:
            info.append("ğŸ® GPU: NÃ£o disponÃ­vel")
            
        # Python & PyTorch
        info.append(f"ğŸ Python: {sys.version.split()[0]}")
        info.append(f"ğŸ”¥ PyTorch: {torch.__version__}")
        
        return "\n".join(info)

# Instanciar aplicaÃ§Ã£o
app = OpenDubbingApp()

# Criar interface Gradio
with gr.Blocks(
    theme=gr.themes.Soft(),
    title="ğŸ¬ Open-Dubbing",
    css="""
    .gradio-container {
        max-width: 800px !important;
        margin: auto !important;
    }
    .status-success { color: #4CAF50; }
    .status-error { color: #f44336; }
    .status-warning { color: #ff9800; }
    """
) as demo:
    
    gr.HTML("""
    <div style="text-align: center; padding: 20px;">
        <h1>ğŸ¬ Open-Dubbing</h1>
        <p>Dublagem automÃ¡tica de vÃ­deos com IA</p>
    </div>
    """)
    
    with gr.Row():
        with gr.Column(scale=2):
            # Upload de vÃ­deo
            video_input = gr.File(
                label="ğŸ“¤ Selecione o vÃ­deo",
                file_types=SUPPORTED_FORMATS,
                file_count="single"
            )
            
            # ConfiguraÃ§Ãµes principais
            with gr.Row():
                target_lang = gr.Dropdown(
                    label="ğŸŒ Idioma de destino",
                    choices=[
                        ("ğŸ‡§ğŸ‡· PortuguÃªs", "por"),
                        ("ğŸ‡ºğŸ‡¸ InglÃªs", "eng"),
                        ("ğŸ‡ªğŸ‡¸ Espanhol", "spa"),
                        ("ğŸ‡«ğŸ‡· FrancÃªs", "fra"),
                        ("ğŸ‡©ğŸ‡ª AlemÃ£o", "deu"),
                        ("ğŸ‡®ğŸ‡¹ Italiano", "ita"),
                        ("ğŸ‡·ğŸ‡º Russo", "rus"),
                        ("ğŸ‡¯ğŸ‡µ JaponÃªs", "jpn"),
                        ("ğŸ‡°ğŸ‡· Coreano", "kor"),
                        ("ğŸ‡¨ğŸ‡³ ChinÃªs", "zho")
                    ],
                    value="por"
                )
                
                source_lang = gr.Dropdown(
                    label="ğŸ¤ Idioma original",
                    choices=[
                        ("ğŸ¤– Detectar automaticamente", "auto"),
                        ("ğŸ‡ºğŸ‡¸ InglÃªs", "eng"),
                        ("ğŸ‡§ğŸ‡· PortuguÃªs", "por"),
                        ("ğŸ‡ªğŸ‡¸ Espanhol", "spa"),
                        ("ğŸ‡«ğŸ‡· FrancÃªs", "fra"),
                        ("ğŸ‡©ğŸ‡ª AlemÃ£o", "deu"),
                        ("ğŸ‡®ğŸ‡¹ Italiano", "ita"),
                        ("ğŸ‡·ğŸ‡º Russo", "rus"),
                        ("ğŸ‡¯ğŸ‡µ JaponÃªs", "jpn"),
                        ("ğŸ‡°ğŸ‡· Coreano", "kor"),
                        ("ğŸ‡¨ğŸ‡³ ChinÃªs", "zho")
                    ],
                    value="auto"
                )
            
            # Token HuggingFace
            hf_token = gr.Textbox(
                label="ğŸ”‘ Token HuggingFace",
                placeholder="hf_...",
                type="password",
                info="NecessÃ¡rio para usar os modelos de IA"
            )
            
            # ConfiguraÃ§Ãµes avanÃ§adas
            with gr.Accordion("âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas", open=False):
                tts_engine = gr.Dropdown(
                    label="ğŸµ Motor TTS",
                    choices=[
                        ("ğŸ”Š Edge TTS (RÃ¡pido)", "edge"),
                        ("ğŸ¤ OpenAI TTS (Melhor)", "openai"),
                        ("ğŸ¤– Coqui TTS (Local)", "coqui")
                    ],
                    value="edge"
                )
                
                use_gpu = gr.Checkbox(
                    label="ğŸ® Usar GPU (se disponÃ­vel)",
                    value=True
                )
            
            # BotÃ£o de processamento
            process_btn = gr.Button(
                "ğŸš€ Iniciar Dublagem",
                variant="primary",
                size="lg"
            )
            
        with gr.Column(scale=1):
            # InformaÃ§Ãµes do sistema
            gr.HTML(f"""
            <div style="background: #f0f0f0; padding: 15px; border-radius: 8px; margin-bottom: 20px;">
                <h3>ğŸ’» Sistema</h3>
                <pre style="font-size: 12px; margin: 0;">{app.get_system_info()}</pre>
            </div>
            """)
            
            # Status
            status_output = gr.Textbox(
                label="ğŸ“Š Status",
                lines=5,
                interactive=False
            )
            
            # Download
            download_output = gr.File(
                label="ğŸ“¥ Download",
                visible=False
            )
    
    # Ãrea de logs
    with gr.Accordion("ğŸ“‹ Logs Detalhados", open=False):
        logs_output = gr.Textbox(
            label="Logs",
            lines=10,
            interactive=False
        )
    
    # Guia de uso
    with gr.Accordion("ğŸ“– Guia de Uso", open=False):
        gr.HTML("""
        <div style="padding: 10px;">
            <h3>ğŸš€ Como usar:</h3>
            <ol>
                <li><strong>Token HuggingFace:</strong> Crie em <a href="https://huggingface.co/settings/tokens" target="_blank">huggingface.co/settings/tokens</a></li>
                <li><strong>Aceite licenÃ§as:</strong> 
                    <ul>
                        <li><a href="https://huggingface.co/pyannote/segmentation-3.0" target="_blank">pyannote/segmentation-3.0</a></li>
                        <li><a href="https://huggingface.co/pyannote/speaker-diarization-3.1" target="_blank">pyannote/speaker-diarization-3.1</a></li>
                    </ul>
                </li>
                <li><strong>Suba seu vÃ­deo</strong> (max 500MB)</li>
                <li><strong>Configure idiomas</strong> e token</li>
                <li><strong>Clique em "Iniciar Dublagem"</strong></li>
            </ol>
            
            <h3>âš¡ Dicas:</h3>
            <ul>
                <li>ğŸ® Use GPU para processar mais rÃ¡pido</li>
                <li>ğŸ“ VÃ­deos menores processam mais rÃ¡pido</li>
                <li>ğŸ”Š Edge TTS Ã© mais rÃ¡pido</li>
                <li>â±ï¸ Processo pode demorar alguns minutos</li>
            </ul>
        </div>
        """)
    
    # Eventos
    def on_process_click(video_file, target_lang, hf_token, source_lang, tts_engine, use_gpu):
        if not video_file:
            return None, "âŒ Selecione um arquivo de vÃ­deo", "", gr.update(visible=False)
        
        result_file, status, logs = app.process_video(
            video_file, target_lang, hf_token, 
            source_lang, tts_engine, use_gpu
        )
        
        if result_file:
            return result_file, status, logs, gr.update(visible=True, value=result_file)
        else:
            return None, status, logs, gr.update(visible=False)
    
    process_btn.click(
        fn=on_process_click,
        inputs=[video_input, target_lang, hf_token, source_lang, tts_engine, use_gpu],
        outputs=[download_output, status_output, logs_output, download_output]
    )

# Executar aplicaÃ§Ã£o
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        inbrowser=True,
        show_error=True
    )
